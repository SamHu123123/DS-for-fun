{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc285ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LassoCV\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.stats import skew\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "def Get_StrColumn_List(X):\n",
    "    str_col_list = []\n",
    "    for col in X.columns:\n",
    "        col_value = next(i for i in X[col] if not pd.isna(i))\n",
    "        if isinstance(col_value, str):\n",
    "            str_col_list.append(col)\n",
    "    return str_col_list\n",
    "\n",
    "def Get_NumberColumn_List(X):\n",
    "    number_col_list = []\n",
    "    for col in X.columns:\n",
    "        col_value = next(i for i in X[col] if not pd.isna(i))\n",
    "        if isinstance(col_value, int) or isinstance(col_value, float):\n",
    "            number_col_list.append(col)\n",
    "    return number_col_list\n",
    "\n",
    "def encode(frame, feature):\n",
    "    # Encode the categories based on the ascending mean sale prices\n",
    "    ordering = pd.DataFrame()\n",
    "    ordering['val'] = frame[feature].unique()\n",
    "    ordering.index = ordering.val\n",
    "    ordering['spmean'] = frame[[feature, 'SalePrice']].groupby(feature).mean()['SalePrice']\n",
    "    ordering = ordering.sort_values('spmean')\n",
    "    ordering['ordering'] = range(1, ordering.shape[0] + 1)\n",
    "    ordering = ordering['ordering'].to_dict()\n",
    "\n",
    "    for cat, o in ordering.items():\n",
    "        frame.loc[frame[feature] == cat, feature + '_E'] = o\n",
    "\n",
    "def FeatureCreation_X(X):\n",
    "\n",
    "    # Create new columns based on the mean of sales price for each string category\n",
    "    str_col_list = Get_StrColumn_List(X)\n",
    "    for col in str_col_list:\n",
    "        encode(X, col)\n",
    "\n",
    "    # Convert yr to age\n",
    "    yr_col = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']\n",
    "    # Correct the future year 2207 to 2007 (typo) in GarageYrBlt found the typo while looking at the data\n",
    "    X.loc[X['GarageYrBlt'] > 2010, 'GarageYrBlt'] = 2007\n",
    "    latestyr = X[yr_col].max().max()\n",
    "    X[yr_col] = X[yr_col].fillna(latestyr)\n",
    "    # Correct the future year 2207 to 2007 (typo) in GarageYrBlt\n",
    "    X.loc[X['GarageYrBlt'] > latestyr, 'GarageYrBlt'] = 2007\n",
    "    X[yr_col] = latestyr - X[yr_col]\n",
    "\n",
    "    # Make new feature columns on area\n",
    "    # GrLivArea = 1stFlrSF + 2ndFlrSF + LowQualFinSF\n",
    "    # TotalBsmtSF = BsmtFinSF1 + BsmtFinSF2 + BsmtUnfSF\n",
    "    # Sometimes 1stFlrSF is same as TotalBsmtSF which we need to adjust (basement same as 1st Floor?)\n",
    "\n",
    "    X['BsmtFinSF'] = X['BsmtFinSF1'] + X['BsmtFinSF2']\n",
    "    X.drop(['BsmtFinSF1', 'BsmtFinSF2'], axis=1, inplace=True)\n",
    "    X['1stFlrSF'] = X['1stFlrSF'] - X['TotalBsmtSF']\n",
    "\n",
    "    X['BadLivAreaPct'] = (X['LowQualFinSF'] + X['BsmtUnfSF']) / X['GrLivArea']\n",
    "    X['GoodLivAreaPct'] = 1 - X['BadLivAreaPct']\n",
    "    X.drop(['1stFlrSF', '2ndFlrSF', 'LowQualFinSF'], axis=1, inplace=True)\n",
    "\n",
    "    X['OutSideArea'] = X['WoodDeckSF'] + X['OpenPorchSF'] + X['EnclosedPorch'] + \\\n",
    "                       X['3SsnPorch'] + X['ScreenPorch'] + X['PoolArea'] + X['MasVnrArea']\n",
    "    X.drop(['WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch',\n",
    "            '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MasVnrArea'], axis=1, inplace=True)\n",
    "\n",
    "    X['TotalBuildingArea'] = X['GrLivArea'] + X['GarageArea'] + X['OutSideArea']\n",
    "    X.drop(['GarageArea', 'OutSideArea'], axis=1, inplace=True)\n",
    "\n",
    "    # Creating the total number of bath\n",
    "    X['Bath'] = X['BsmtFullBath'] + X['FullBath'] + (X['BsmtHalfBath'] + X['HalfBath']) * 0.5\n",
    "    X.drop(['BsmtFullBath', 'FullBath', 'BsmtHalfBath', 'HalfBath'], axis=1, inplace=True)\n",
    "\n",
    "    # Creating flag for remodelling\n",
    "    X['Is_Remodelled'] = np.where(X['YearRemodAdd'] != X['YearBuilt'], 1, 0)\n",
    "\n",
    "    # Creating flag for remodelling just before sale:-\n",
    "    X['Is_ReMdlB4Sale'] = np.where(abs(X['YrSold'] - X['YearRemodAdd']) <= 1, 1, 0)\n",
    "\n",
    "    return X\n",
    "\n",
    "# Import the data\n",
    "test = pd.read_csv('test.csv', index_col=0)\n",
    "train = pd.read_csv('train.csv', index_col=0)\n",
    "submission = pd.read_csv('sample_submission.csv', index_col=0)\n",
    "\n",
    "# Obtaining the y and X for the data\n",
    "y = train['SalePrice']\n",
    "# Combine both the test and train X data\n",
    "X = pd.concat([train, test], ignore_index=True)\n",
    "# Remove columns with more than 70% nulls\n",
    "col_list_null = X.isna().sum() / len(X)\n",
    "X = X.loc[:, col_list_null < 0.7]\n",
    "# Adjust the skewed numerical columns\n",
    "number_col_list = Get_NumberColumn_List(X)\n",
    "skew_features = X[number_col_list].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "high_skew = skew_features[skew_features > 0.5]\n",
    "skew_index = high_skew.index\n",
    "for i in skew_index:\n",
    "    X[i] = boxcox1p(X[i], boxcox_normmax(X[i] + 1))\n",
    "# Create new features columns based on string columns\n",
    "X = FeatureCreation_X(X)\n",
    "# Fill na with the mode for str columns and 0 for number columns\n",
    "for col in Get_StrColumn_List(X):\n",
    "    X[col].fillna(X[col].mode()[0], inplace=True)\n",
    "X.fillna(0, inplace=True)\n",
    "# Encode and adjust skew for numerical columns\n",
    "X_mod = pd.get_dummies(X).reset_index(drop=True)\n",
    "y_mod = np.log1p(y)\n",
    "Xtest_mod = X_mod.loc[X_mod['SalePrice'] == 0, X_mod.columns != 'SalePrice']\n",
    "Xtrain_mod = X_mod.loc[X_mod['SalePrice'] != 0, X_mod.columns != 'SalePrice']\n",
    "\n",
    "# Feature reduction with recursive feature elimination ============================================================\n",
    "# X_train, X_test, y_train, y_test = train_test_split(Xtrain_mod, y_mod, test_size=0.2, random_state=0)\n",
    "# rfe_rf = RFE(estimator=RandomForestRegressor(), n_features_to_select=100, step=10, verbose=1)\n",
    "# rfe_rf.fit(X_train, y_train)\n",
    "# rf_mask = rfe_rf.support_\n",
    "# rfe_gb = RFE(estimator=GradientBoostingRegressor(), n_features_to_select=100, step=10, verbose=1)\n",
    "# rfe_gb.fit(X_train, y_train)\n",
    "# gb_mask = rfe_gb.support_\n",
    "# votes = np.sum([rf_mask, gb_mask], axis=0)\n",
    "# mask = votes >= 2\n",
    "# Xtrain_mod_mask = Xtrain_mod.loc[:, mask]\n",
    "# Xtest_mod_mask = Xtest_mod.loc[:, mask]\n",
    "\n",
    "# # specify your configurations as a dict for lightgbm ============================================================\n",
    "# from shaphypetune import BoostSearch\n",
    "#\n",
    "# param_grid_1 = {'learning_rate': [0.01],\n",
    "#                 'n_estimators': [500],\n",
    "#                 'num_leaves': [10, 20, 30, 40],\n",
    "#                 'max_depth': [5, 6, 7, 8, 9, 10],\n",
    "#                 'boosting': [\"gbdt\", \"dart\", \"goss\"]}\n",
    "#\n",
    "# model = BoostSearch(LGBMRegressor(), param_grid=param_grid_1)\n",
    "# model.fit(X_train, y_train, eval_set=[(X_test, y_test)], early_stopping_rounds=6, verbose=0)\n",
    "#\n",
    "# best_param = {'learning_rate': 0.01,\n",
    "#               'n_estimators': 500,\n",
    "#               'num_leaves': 20,\n",
    "#               'max_depth': 10,\n",
    "#               'boosting': \"gbdt\"}\n",
    "\n",
    "# specify your configurations as a dict for lightgbm ==============================================================\n",
    "mdl_pred_prf = pd.DataFrame(data=None, index=submission.index, columns=None)\n",
    "RMSE = pd.DataFrame(columns=['RmseTest_STACK', 'RmseTrain_STACK'])\n",
    "nb_mdl = 10\n",
    "k = 0\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
    "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
    "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
    "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n",
    "\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
    "ridge_model_full_data = ridge.fit(Xtrain_mod, y_mod)\n",
    "\n",
    "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=100000, alphas=alphas2, random_state=42, cv=kfolds))\n",
    "lasso_model_full_data = lasso.fit(Xtrain_mod, y_mod)\n",
    "\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=100000, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))\n",
    "elastic_model_full_data = elasticnet.fit(Xtrain_mod, y_mod)\n",
    "\n",
    "lgb = LGBMRegressor(boosting_type='gbdt', objective='regression', num_leaves=20,\n",
    "                    learning_rate=0.01, n_estimators=500, max_depth=10, metric='rmse')\n",
    "lgb_model_full_data = lgb.fit(Xtrain_mod, y_mod)\n",
    "\n",
    "svr = make_pipeline(RobustScaler(), SVR(C=20, epsilon=0.008, gamma=0.0003,))\n",
    "svr_model_full_data = svr.fit(Xtrain_mod, y_mod)\n",
    "\n",
    "xgboost = XGBRegressor(learning_rate=0.01, n_estimators=3460, max_depth=3, min_child_weight=0,\n",
    "                       gamma=0, subsample=0.7, colsample_bytree=0.7, nthread=-1,\n",
    "                       scale_pos_weight=1, seed=27, reg_alpha=0.00006)\n",
    "xgb_model_full_data = xgboost.fit(Xtrain_mod, y_mod)\n",
    "\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01, max_depth=6, n_estimators=500, subsample=0.5)\n",
    "gbr_model_full_data = gbr.fit(Xtrain_mod, y_mod)\n",
    "\n",
    "level0 = list()\n",
    "level0.append(('ridge', ridge))\n",
    "level0.append(('lasso', lasso))\n",
    "level0.append(('elasticnet', elasticnet))\n",
    "level0.append(('lgb', lgb))\n",
    "level0.append(('svr', svr))\n",
    "level0.append(('xgb', xgboost))\n",
    "# define meta learner model\n",
    "level1 = gbr\n",
    "# define the stacking ensemble\n",
    "stack_model = StackingRegressor(estimators=level0, final_estimator=level1, cv=5, n_jobs=-1)\n",
    "# fit the model on all available data\n",
    "stack_model.fit(Xtrain_mod, y_mod)\n",
    "\n",
    "def blend_models_predict(X):\n",
    "    return ((0.1 * elastic_model_full_data.predict(X)) + (0.05 * lasso_model_full_data.predict(X)) +\n",
    "            (0.1 * ridge_model_full_data.predict(X)) + (0.1 * svr_model_full_data.predict(X)) +\n",
    "            (0.1 * gbr_model_full_data.predict(X)) + (0.15 * xgb_model_full_data.predict(X)) +\n",
    "            (0.1 * lgb_model_full_data.predict(X)) + (0.3 * stack_model.predict(np.array(X))))\n",
    "\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X=X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
    "    return (rmse)\n",
    "\n",
    "submission['SalePrice'] = np.expm1(blend_models_predict(Xtest_mod))\n",
    "submission.to_csv('sub9.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
